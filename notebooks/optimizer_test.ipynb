{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T15:34:30.353658Z",
     "start_time": "2024-10-14T15:34:28.475832Z"
    }
   },
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import kfac_jax\n",
    "\n",
    "# Hyper parameters\n",
    "NUM_CLASSES = 10\n",
    "L2_REG = 1e-3\n",
    "NUM_BATCHES = 100\n",
    "\n",
    "\n",
    "def make_dataset_iterator(batch_size):\n",
    "  # Dummy dataset, in practice this should be your dataset pipeline\n",
    "  for _ in range(NUM_BATCHES):\n",
    "    yield jnp.zeros([batch_size, 100]), jnp.ones([batch_size], dtype=\"int32\")\n",
    "\n",
    "\n",
    "def softmax_cross_entropy(logits: jnp.ndarray, targets: jnp.ndarray):\n",
    "  \"\"\"Softmax cross entropy loss.\"\"\"\n",
    "  # We assume integer labels\n",
    "  assert logits.ndim == targets.ndim + 1\n",
    "\n",
    "  # Tell KFAC-JAX this model represents a classifier\n",
    "  # See https://kfac-jax.readthedocs.io/en/latest/overview.html#supported-losses\n",
    "  kfac_jax.register_softmax_cross_entropy_loss(logits, targets)\n",
    "  log_p = jax.nn.log_softmax(logits, axis=-1)\n",
    "  return - jax.vmap(lambda x, y: x[y])(log_p, targets)\n",
    "\n",
    "\n",
    "def model_fn(x):\n",
    "  \"\"\"A Haiku MLP model function - three hidden layer network with tanh.\"\"\"\n",
    "  return hk.nets.MLP(\n",
    "    output_sizes=(50, 50, 50, NUM_CLASSES),\n",
    "    with_bias=True,\n",
    "    activation=jax.nn.tanh,\n",
    "  )(x)\n",
    "\n",
    "\n",
    "# The Haiku transformed model\n",
    "hk_model = hk.without_apply_rng(hk.transform(model_fn))\n",
    "\n",
    "\n",
    "def loss_fn(model_params, model_batch):\n",
    "  \"\"\"The loss function to optimize.\"\"\"\n",
    "  x, y = model_batch\n",
    "  logits = hk_model.apply(model_params, x)\n",
    "  loss = jnp.mean(softmax_cross_entropy(logits, y))\n",
    "\n",
    "  # The optimizer assumes that the function you provide has already added\n",
    "  # the L2 regularizer to its gradients.\n",
    "  return loss + L2_REG * kfac_jax.utils.inner_product(params, params) / 2.0\n",
    "\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = kfac_jax.Optimizer(\n",
    "  value_and_grad_func=jax.value_and_grad(loss_fn),\n",
    "  l2_reg=L2_REG,\n",
    "  value_func_has_aux=False,\n",
    "  value_func_has_state=False,\n",
    "  value_func_has_rng=False,\n",
    "  use_adaptive_learning_rate=True,\n",
    "  use_adaptive_momentum=True,\n",
    "  use_adaptive_damping=True,\n",
    "  initial_damping=1.0,\n",
    "  multi_device=False,\n",
    ")\n",
    "\n",
    "input_dataset = make_dataset_iterator(128)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "dummy_images, dummy_labels = next(input_dataset)\n",
    "rng, key = jax.random.split(rng)\n",
    "params = hk_model.init(key, dummy_images)\n",
    "rng, key = jax.random.split(rng)\n",
    "opt_state = optimizer.init(params, key, (dummy_images, dummy_labels))\n",
    "\n",
    "loss = []\n",
    "\n",
    "# Training loop\n",
    "for i, batch in enumerate(input_dataset):\n",
    "  rng, key = jax.random.split(rng)\n",
    "  params, opt_state, stats = optimizer.step(\n",
    "      params, opt_state, key, batch=batch, global_step_int=i)\n",
    "  loss.append(stats['loss'])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3147df210>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:34:30.365497Z",
     "start_time": "2024-10-14T15:34:30.359998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Type definitions that can be reused across the VMCNet codebase.\n",
    "\n",
    "Because type-checking with numpy/jax numpy can be tricky and does not always agree with\n",
    "type-checkers, this package uses types for static type-checking when possible, but\n",
    "otherwise they are intended for documentation and clarity.\n",
    "\"\"\"\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, TypeVar, Union\n",
    "\n",
    "from jax import Array\n",
    "from jax.typing import ArrayLike\n",
    "import kfac_jax\n",
    "import optax\n",
    "\n",
    "# Currently using PyTree = Any just to improve readability in the code.\n",
    "# A pytree is a \"tree-like structure built out of container-like Python objects\": see\n",
    "# https://jax.readthedocs.io/en/latest/pytrees.html\n",
    "PyTree = Any\n",
    "\n",
    "# TypeVar for an arbitrary PyTree\n",
    "T = TypeVar(\"T\", bound=PyTree)\n",
    "\n",
    "# TypeVar for a pytree containing MCMC data, e.g. walker positions\n",
    "# and wave function amplitudes, or other auxiliary MCMC data\n",
    "D = TypeVar(\"D\", bound=PyTree)\n",
    "\n",
    "# TypeVar for MCMC metadata which is required to take a metropolis step.\n",
    "M = TypeVar(\"M\", bound=PyTree)\n",
    "\n",
    "# TypeVar for a pytree containing model params\n",
    "P = TypeVar(\"P\", bound=PyTree)\n",
    "\n",
    "# TypeVar for a pytree containing optimizer state\n",
    "S = TypeVar(\"S\", bound=PyTree)\n",
    "\n",
    "# Actual optimizer states currently used\n",
    "# TODO: Figure out how to make kfac_opt.State not be interpreted by mypy as Any\n",
    "OptimizerState = Union[kfac_jax.optimizer.OptimizerState, optax.OptState]\n",
    "\n",
    "LearningRateSchedule = Callable[[Array], Array]\n",
    "\n",
    "ModelParams = Dict[str, Any]\n",
    "\n",
    "# VMC state needed for a checkpoint. Values are:\n",
    "#  1. The epoch\n",
    "#  2. The MCMC walker data\n",
    "#  3. The model parameters\n",
    "#  4. The optimizer state\n",
    "#  5. The RNG key\n",
    "#CheckpointData = Tuple[int, D, P, S, PRNGKey]\n",
    "\n",
    "ArrayList = List[Array]\n",
    "\n",
    "# Single array in (sign, logabs) form\n",
    "SLArray = Tuple[Array, Array]\n",
    "\n",
    "SLArrayList = List[SLArray]\n",
    "\n",
    "ParticleSplit = Union[int, Sequence[int]]\n",
    "\n",
    "InputStreams = Tuple[Array, Optional[Array], Optional[Array], Optional[Array]]\n",
    "ComputeInputStreams = Callable[[Array], InputStreams]\n",
    "\n",
    "Backflow = Callable[[Array, Optional[Array]], Array]\n",
    "\n",
    "Jastrow = Callable[[Array, Array, Array, Array, Array], Array]\n",
    "\n",
    "ModelApply = Callable[[P, Array], Array]\n",
    "#LocalEnergyApply = Callable[[P, Array, Optional[PRNGKey]], Array]\n",
    "\n",
    "GetPositionFromData = Callable[[D], Array]\n",
    "GetAmplitudeFromData = GetPositionFromData[D]\n",
    "UpdateDataFn = Callable[[D, P], D]\n",
    "\n",
    "ClippingFn = Callable[[Array, ArrayLike], Array]"
   ],
   "id": "fef521b03ab982b9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:34:30.378666Z",
     "start_time": "2024-10-14T15:34:30.368534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Required code for the Spring optimizer\n",
    "import functools\n",
    "from typing import Callable\n",
    "from jax import core\n",
    "\n",
    "def wrap_if_pmap(p_func: Callable) -> Callable:\n",
    "    \"\"\"Make a function run if in a pmapped context.\"\"\"\n",
    "\n",
    "    def p_func_if_pmap(obj, axis_name):\n",
    "        try:\n",
    "            core.axis_frame(axis_name)\n",
    "            return p_func(obj, axis_name)\n",
    "        except NameError:\n",
    "            return obj\n",
    "\n",
    "    return p_func_if_pmap\n",
    "\n",
    "pmean_if_pmap = functools.partial(wrap_if_pmap(jax.lax.pmean), axis_name=\"pmap_axis\")\n",
    "\n",
    "\"\"\"Helper functions for pytrees.\"\"\"\n",
    "import chex\n",
    "import jax.flatten_util\n",
    "\n",
    "\n",
    "def tree_sum(tree1: T, tree2: T) -> T:\n",
    "    \"\"\"Leaf-wise sum of two pytrees with the same structure.\"\"\"\n",
    "    return jax.tree_map(lambda a, b: a + b, tree1, tree2)\n",
    "\n",
    "\n",
    "def tree_diff(tree1: T, tree2: T) -> T:\n",
    "    \"\"\"Leaf-wise sum of two pytrees with the same structure.\"\"\"\n",
    "    return jax.tree_map(lambda a, b: a - b, tree1, tree2)\n",
    "\n",
    "\n",
    "def tree_dist(tree1: T, tree2: T, mode=\"squares\") -> Array:\n",
    "    \"\"\"Distance between two pytrees with the same structure.\"\"\"\n",
    "    dT = tree_diff(tree1, tree2)\n",
    "    if mode == \"squares\":\n",
    "        return tree_inner_product(dT, dT)\n",
    "    raise ValueError(f\"Unknown mode {mode}\")\n",
    "\n",
    "\n",
    "def tree_prod(tree1: T, tree2: T) -> T:\n",
    "    \"\"\"Leaf-wise product of two pytrees with the same structure.\"\"\"\n",
    "    return jax.tree_map(lambda a, b: a * b, tree1, tree2)\n",
    "\n",
    "\n",
    "def multiply_tree_by_scalar(tree: T, scalar: chex.Numeric) -> T:\n",
    "    \"\"\"Multiply all leaves of a pytree by a scalar.\"\"\"\n",
    "    return jax.tree_map(lambda x: scalar * x, tree)\n",
    "\n",
    "\n",
    "def tree_inner_product(tree1: T, tree2: T) -> Array:\n",
    "    \"\"\"Inner product of two pytrees with the same structure.\"\"\"\n",
    "    leaf_inner_prods = jax.tree_map(lambda a, b: jnp.sum(a * b), tree1, tree2)\n",
    "    return jnp.sum(jax.flatten_util.ravel_pytree(leaf_inner_prods)[0])\n",
    "\n",
    "\n",
    "def tree_reduce_l1(xs: PyTree) -> chex.Numeric:\n",
    "    \"\"\"L1 norm of a pytree as a flattened vector.\"\"\"\n",
    "    concat_xs, _ = jax.flatten_util.ravel_pytree(xs)\n",
    "    return jnp.sum(jnp.abs(concat_xs))"
   ],
   "id": "b4df4a5d3812ea2c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:34:30.392823Z",
     "start_time": "2024-10-14T15:34:30.382904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Stochastic reconfiguration (SR) routine.\"\"\"\n",
    "import jax\n",
    "import jax.flatten_util\n",
    "import jax.numpy as jnp\n",
    "\n",
    "#from vmcnet.utils.typing import Array, ModelApply, P, Tuple\n",
    "\n",
    "import chex\n",
    "\n",
    "\n",
    "\n",
    "def get_spring_update_fn(\n",
    "    log_psi_apply: ModelApply[P],\n",
    "    damping: chex.Scalar = 0.001,\n",
    "    mu: chex.Scalar = 0.99,\n",
    "    momentum: chex.Scalar = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the SPRING update function.\n",
    "\n",
    "    Args:\n",
    "        log_psi_apply (Callable): computes log|psi(x)|, where the signature of this\n",
    "            function is (params, x) -> log|psi(x)|\n",
    "        damping (float): damping parameter\n",
    "        mu (float): SPRING-specific regularization\n",
    "\n",
    "    Returns:\n",
    "        Callable: SPRING update function. Has the signature\n",
    "        (centered_energies, params, prev_grad, positions) -> new_grad\n",
    "    \"\"\"\n",
    "\n",
    "    def raveled_log_psi_grad(params: P, positions: Array) -> Array:\n",
    "        log_grads = jax.grad(log_psi_apply)(params, positions)\n",
    "        return jax.flatten_util.ravel_pytree(log_grads)[0]\n",
    "\n",
    "    batch_raveled_log_psi_grad = jax.vmap(raveled_log_psi_grad, in_axes=(None, 0))\n",
    "\n",
    "    def spring_update_fn(\n",
    "        centered_energies: P,\n",
    "        params: P,\n",
    "        prev_grad,\n",
    "        positions: Array,\n",
    "    ) -> Tuple[Array, P]:\n",
    "        nchains = positions.shape[0]\n",
    "\n",
    "        prev_grad, unravel_fn = jax.flatten_util.ravel_pytree(prev_grad)\n",
    "        prev_grad_decayed = mu * prev_grad\n",
    "\n",
    "        log_psi_grads = batch_raveled_log_psi_grad(params, positions) / jnp.sqrt(\n",
    "            nchains\n",
    "        )\n",
    "        Ohat = log_psi_grads - jnp.mean(log_psi_grads, axis=0, keepdims=True) # Equation (9)\n",
    "\n",
    "        T = Ohat @ Ohat.T\n",
    "        ones = jnp.ones((nchains, 1))\n",
    "        T_reg = T + ones @ ones.T / nchains + damping * jnp.eye(nchains) # Inner bracket of Equation (32)\n",
    "\n",
    "        epsilon_bar = centered_energies / jnp.sqrt(nchains)\n",
    "        epsion_tilde = epsilon_bar - Ohat @ prev_grad_decayed    # Given above Equation (31)\n",
    "\n",
    "        dtheta_residual = Ohat.T @ jax.scipy.linalg.solve(\n",
    "            T_reg, epsion_tilde, assume_a=\"pos\"\n",
    "        )                                                               # Equation (32)\n",
    "\n",
    "        SR_G = dtheta_residual + prev_grad_decayed                      # Equation (33)\n",
    "        SR_G = (1 - momentum) * SR_G + momentum * prev_grad             # Equation (34)\n",
    "\n",
    "        return unravel_fn(SR_G)\n",
    "\n",
    "    return spring_update_fn\n",
    "\n",
    "\n",
    "def constrain_norm(\n",
    "    grad: P,\n",
    "    norm_constraint: chex.Numeric = 0.001,\n",
    ") -> P:\n",
    "    \"\"\"Euclidean norm constraint.\"\"\"\n",
    "    sq_norm_scaled_grads = tree_inner_product(grad, grad)\n",
    "\n",
    "    # Sync the norms here, see:\n",
    "    # https://github.com/deepmind/deepmind-research/blob/30799687edb1abca4953aec507be87ebe63e432d/kfac_ferminet_alpha/optimizer.py#L585\n",
    "    sq_norm_scaled_grads = pmean_if_pmap(sq_norm_scaled_grads)\n",
    "\n",
    "    norm_scale_factor = jnp.sqrt(norm_constraint / sq_norm_scaled_grads)\n",
    "    coefficient = jnp.minimum(norm_scale_factor, 1)\n",
    "    constrained_grads = multiply_tree_by_scalar(grad, coefficient)\n",
    "\n",
    "    return constrained_grads"
   ],
   "id": "cf7fac9814e3c03a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T19:28:50.330648Z",
     "start_time": "2024-10-24T19:28:50.325008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "S = [[-0.01, 0.00095, 0.0005], [0.08, -0.1, 0.02], [0,0,-1]]\n",
    "S = np.array(S)\n",
    "alpha = np.array([1,0,0])\n",
    "print('pi = ', (alpha@np.linalg.inv(-S))/(alpha@np.linalg.inv(-S)@np.ones(3)))\n",
    "print(S)"
   ],
   "id": "37369489aaa919b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi =  [9.89912789e-01 9.40417149e-03 6.83039824e-04]\n",
      "[[-1.0e-02  9.5e-04  5.0e-04]\n",
      " [ 8.0e-02 -1.0e-01  2.0e-02]\n",
      " [ 0.0e+00  0.0e+00 -1.0e+00]]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T19:29:21.276100Z",
     "start_time": "2024-10-24T19:29:21.272420Z"
    }
   },
   "cell_type": "code",
   "source": "1/6.83039824e-04",
   "id": "6c114e5d86286b3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464.0434786713108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T19:24:02.251248Z",
     "start_time": "2024-10-24T19:24:02.247534Z"
    }
   },
   "cell_type": "code",
   "source": "5487/12",
   "id": "97ff5a66f0b3f191",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T19:24:39.172464Z",
     "start_time": "2024-10-24T19:24:39.169114Z"
    }
   },
   "cell_type": "code",
   "source": "5000/5487",
   "id": "af79cbaed6cd826b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911244760342628"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T19:25:19.715025Z",
     "start_time": "2024-10-24T19:25:19.711563Z"
    }
   },
   "cell_type": "code",
   "source": "12/5487",
   "id": "317412cdb6044575",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002186987424822307"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e6c18cffc35b099"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
